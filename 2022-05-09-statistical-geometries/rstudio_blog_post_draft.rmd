---
title: "{ggxmean} and new statistical geoms"
author: "Gina Reynolds, Morgan Brown, Madison McGovern"
date: "5/11/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
usma = T
```

# TL;DR

The ggxmean package introduces new geom\_\* for fluid visual description of some basic statistical concepts, the title character, geom_x\_mean, which draws a vertical line at the mean of x.  We also introduce "Easy Geom Recipes", an introductory tutorial for creating a class of geoms that perform useful computation and inherit characteristics from more primitive geoms. 

# On the path to {ggxmean}: 

Some time ago, I was sitting on the floor in the back of a packed-out ballroom, watching Thomas Lin Pederson give a talk: ['Extend your Ability to Extend ggplot2'](https://www.youtube.com/watch?v=uj7A3i2fi54).

'I want to do that' I thought to myself, like the hundreds of others there!

And I had a use case: statistical summaries, especially those for explaining rather basic statistical concepts like variance, covariance, and correlation.

<!-- https://evamaerey.github.io/statistics/covariance_correlation.html -->



```{=html}
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
```

I'd been working on visual walk-throughs of these concepts for courses I'd taught. At a chalkboard, you can walk through these ideas pretty easily.  


I also wanted to do walk throughs w/ ggplot2.  

<blockquote class="twitter-tweet">

<p lang="en" dir="ltr">

So, math notation and visual representation builds of basic statistics! They co-evolve speaking to different learning styles. Plus DRY principles for coders and a walk through of calc w num vals, for numerophiles! <a href="https://twitter.com/hashtag/ggplot2?src=hash&amp;ref_src=twsrc%5Etfw">\#ggplot2</a> <a href="https://twitter.com/hashtag/xaringan?src=hash&amp;ref_src=twsrc%5Etfw">\#xaringan</a> <a href="https://twitter.com/hashtag/flipbookr?src=hash&amp;ref_src=twsrc%5Etfw">\#flipbookr</a> <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">\#rstats</a> <a href="https://t.co/JgWLxo94Ms">https://t.co/JgWLxo94Ms</a> <a href="https://t.co/ol08lMGdtD">pic.twitter.com/ol08lMGdtD</a>

</p>

--- Gina Reynolds (@EvaMaeRey) <a href="https://twitter.com/EvaMaeRey/status/1276260233577238528?ref_src=twsrc%5Etfw">June 25, 2020</a>

</blockquote>

I managed to pull this together, but there was so much prep that had to happen before you could do this start with the visualization. I calculated the means, standard deviations etc, all before beginning to plot, and then fed those calculations into existing geom functions like geom_vline and geom_segment.

But this didn't feel like the powerful declarative experience that you have a lot of the time using ggplot2. For example, the boxplot experience is:

a. I want to know about the pattern in this dataset; okay, so `ggplot(data = my_data)`

b. I'm picturing my different categories on the x axis; alright, `mapping = aes(x = my_category)`

c. And I'd like y to represent my continous variable; great, then `mapping = aes(y = my_continuous_outcome)`

d.  And I'll use boxplots to summarize these groupwise distributions; so it's `'+ geom_boxplot()'`.

e.  and bam! I've built my plot and I can see group differences!

In this boxplot example, lots of computation happens in the background for us: min, max, 25%, 75%, median. And that is great. I understand the boxplot well; I don't need to do those computations myself. I'm happy for ggplot2 to that for me.

For this stats walk through, I wanted the same declarative experience. I understand the mean well, and one standard deviation away from the mean, etc. I should be able to ask ggplot2 to do that computation for me -- to compute the global mean (or a group-wise mean if I'm in the mood for that) -- and put a vertical line there. 

But as things stood, my solution to choreographing the stats visualizations felt inelegant and fragile. It wasn't portable (not easy to move to other cases -- maybe data that I or my students might be more passionate about) or dynamic (I couldn't easily do group-wise work instead of acting globally). Put simply, it wasn't very fun.

Thomas' talk and the extension system seemed like the answer to bringing ggplot2 fun to this the statistical storytelling that I'd been wanting to do. 

Fast forward a few years.  I've dug into tutorial material like the ['Extending ggplot2' vignette](https://cran.r-project.org/web/packages/ggplot2/vignettes/extending-ggplot2.html) and the ['Extension'](https://ggplot2-book.org/extensions.html) chapter in the newest edition of the ggplot2 book, rewatched Thomas Lin Pederson's talk a number of times, and examined [ggplot2 code on github](https://github.com/tidyverse/ggplot2/blob/main/R/geom-vline.r) and code from other extension packages in the [ggplot2 extension gallery](https://exts.ggplot2.tidyverse.org/gallery/).  And now I'm happy to introduce the [{ggxmean}](https://github.com/EvaMaeRey/ggxmean) package!

The ggxmean package allows you to easily add statistical summaries to your data visualization with new geom functions!  It makes doing statistical walk-throughs like the covariance, variance, sd, and correlation walk-through elegant and fluid!  The syntax mirrors how you might go about untangling the covariance equation and applying it to a scatter plot on a classroom chalkboard! Plus, you can easily ask ggplot2 to do all these computations group-wise if you so choose -- in the example that follows, ggplot recomputes everything for us when we add the faceting by species declaration. Yahoo! That is awesome; ggplot2 hard at work; doing the most. [footnote: some of these functions aren't exported because I'm not confident of the names.]

```{r, message=F, warning=F}
library(tidyverse)
library(ggxmean)
palmerpenguins::penguins %>% 
  ggplot() +
  aes(x = bill_length_mm) +
  aes(y = flipper_length_mm) +
  geom_point() +
  ggxmean::geom_x_mean() +
  ggxmean::geom_y_mean() +
  ggxmean:::geom_xdiff() +
  ggxmean:::geom_ydiff() +
  ggxmean:::geom_x1sd(linetype = "dashed") +
  ggxmean:::geom_y1sd(linetype = "dashed") +
  ggxmean:::geom_diffsmultiplied() +
  ggxmean:::geom_xydiffsmean(alpha = 1) +
  ggxmean:::geom_rsq1() +
  ggxmean:::geom_corrlabel() +
  facet_wrap(facets = vars(species))
```

<!-- <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Excited to be working on a ggplot2 extension package!!! ðŸ˜®ðŸ¥³ðŸ¤¯ <a href="https://twitter.com/hashtag/ggplot2?src=hash&amp;ref_src=twsrc%5Etfw">#ggplot2</a><br><br>{ggxmean} lets you put a vertical line at the mean of x w/ geom_xmean() and do other stuff! <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">#rstats</a><br><br>In action: <a href="https://t.co/oxzudwlNXn">https://t.co/oxzudwlNXn</a> <br><br>Repo: <a href="https://t.co/7DTxa7n4ye">https://t.co/7DTxa7n4ye</a><br><br>Some thoughts in ðŸ§µ <a href="https://t.co/vRjXFdmAaQ">pic.twitter.com/vRjXFdmAaQ</a></p>&mdash; Gina Reynolds (@EvaMaeRey) <a href="https://twitter.com/EvaMaeRey/status/1353484900385628166?ref_src=twsrc%5Etfw">January 24, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> -->

# Way leads onto way ...

At the time I got more comfortable building these new functions, I was also interested visualizing a typical introduction to ordinary least squares (OLS) regression.  What does an instructor draw as the named concepts in teaching linear regression?  Could we isolate those concepts and provide geoms to build up those ideas in code, just as an instructor would do on a chalkboard? This exercise lead to a number of new geoms including those that compute and draw residuals, the intercept, fitted values and more. 


```{r ols}
library(tidyverse)
library(ggxmean)
#library(transformr) #might help w/ animate

## basic example code
cars %>% 
  ggplot() +
  aes(x = speed,
      y = dist) +
  geom_point() + 
  ggxmean::geom_lm() +
  ggxmean::geom_lm_residuals(linetype = "dashed") +
  ggxmean::geom_lm_fitted(color = "goldenrod3", size = 3) +
  ggxmean::geom_lm_conf_int() +
  ggxmean::geom_lm_pred_int() +
  ggxmean::geom_lm_formula() +
  ggxmean::geom_lm_intercept(color = "red", size = 5) +
  ggxmean::geom_lm_intercept_label(size = 4, hjust = 0)
```


# extending the scope of ggxmean: student contributions

The work on OLS was a jumping off point for the most recent additions to the ggxmean package, written by students at West Point, Morgan Brown and Madison McGovern.  Brown and McGovern took up the question of data outliers.

Let's have a look at their work using Anscombe's quartet.  With the functions I'd worked on, we can *visualize* the summary statistics (mean, sds, correlation) that are typically the subject of Anscombe's quartet discussions:

```{r anscomb1, warning=F}
datasets::anscombe %>%
  pivot_longer(cols = 1:8) %>%
  mutate(group = paste("Anscombe", 
                       str_extract(name, "\\d"))) %>%
  mutate(var = str_extract(name, "\\w")) %>%
  select(-name) %>%
  pivot_wider(names_from = var,
              values_from = value) %>%
  unnest() ->
tidy_anscombe

tidy_anscombe %>%
  ggplot() +
  aes(x = x, y = y) +
  geom_point() +
  aes(color = group) +
  facet_wrap(facets = vars(group)) +
  ggxmean::geom_x_mean() +
  ggxmean::geom_y_mean() +
  ggxmean:::geom_x1sd(linetype = "dashed") +
  ggxmean:::geom_y1sd(linetype = "dashed") +
  ggxmean::geom_lm() +
  ggxmean::geom_lm_formula() +
  ggxmean:::geom_corrlabel() + 
  guides(color = "none")
```

<!-- This is cool. Usually we are told "and these four datasets all have the same mean, sds, correlation", with the numeric values possibly provided in a nearby table. And now we get to *see* the values right in our plot!  -->

But, also Anscomb's quartet raises the question, don't we have statistics that will identify outlying observations? The distributions in Anscombs quartet are pretty wonky.  What do other statistics have to 'say' about them?

Morgan and Madison tackled visualizing some additional statistical concepts that speak to less well behaved data: leverage and influence. Morgan Brown's  function geom_text_leverage() calculates leverage for each observation.

```{r anscomb}
tidy_anscombe %>%
  ggplot() +
  aes(x = x, y = y) +
  aes(color = group) +
  geom_point() +
  facet_wrap(facets = vars(group)) +
  ggxmean::geom_text_leverage(vjust = 1,   ## Morgan's function!
                              check_overlap = T) + 
  guides(color = "none")
```
And let's take a quick look at geom_point_high_cooks() which Madison McGovern wrote to highlight the 10% most influential observations, using the datasaurus_dozen from the datasauRus package.

```{r dino}
datasauRus::datasaurus_dozen %>%
  ggplot() +
  aes(x = x, y = y) +
  geom_point() +
  ggxmean::geom_point_high_cooks( ## Madison's function
    color = "goldenrod",
    size = 5) + 
  facet_wrap(facets = "dataset")




```

## Where to stop?

As a guide, I think a geom_*() function may be in order when we have well articulated statistical concepts and would like the visual vocabulary to match. 


#  Extending the circle of extenders with new point of entry: 'easy geom recipes'? 

Learning the particular mechanism needed to build ggxmean functions took me a chunk of time - about six months. Once worked out, though, I found that mechanism to be really enabling --- writing about 20 geom_* functions in ggxmean with this mechanism.   

Working with Morgan and Madison was chance to think more about this particular extension mechanism, and about how to make it accessible to new learners.  Morgan and Madison are top students in the West Point math department, but relative newcomers to R and ggplot2; and yet they managed to write usable geom extensions in less time than I'd done!  

And not only did they write geoms about outlying observations -- arguably more statistically interesting than any of the geoms I'd worked on -- but the also wrote what are, at first glance the most trivial geoms: geom_label_id and geom_coordinate.  

```{r}
ggplot(cars) + 
  aes(x = speed, y = dist) + 
  geom_point() + 
  ggxmean::geom_text_coordinate(hjust = -.05,
                                check_overlap = T)
```

And they put together these additional geoms very quickly and with very little guidance.  Their competence at translating their skills along with the computational accessibility of these more 'trivial' geoms was exciting.  Could we make this space much more accessible to a lot more ggplot2 practitioners?


In a second independent study term, Morgan and I put together tutorial 'easy geom recipes'; and have tested the tutorial with extension newcomers. We distilled down our process for success in building geoms in {ggxmean}.  



For almost all of the geoms in ggxmean we followed the formula:

1)  Step 0: use base ggplot2 to build the desired output

2)  Step 1-3: build your ggplot2 function by

    a)  writing a compute function based on computations done using the base ggplot2 build (we only use compute_group for these easy recipes)
    b)  passing the compute_group function to create a ggproto object
    c)  passing the ggproto object ('Stat') to a geom\_\* function

3)  Step 4: try out and enjoy the geom_*() functionality...

The mechanism is creating geoms_*() that wrap a stat and inherits from an existing geom, and that use continuous required aesthetics.  We think that using inheritance mechanism may be a useful point of entry -- with easy wins -- for folks interested in entering this space!


The tutorial contains 6 recipes - three that are fully worked out, and three that we invite users to complete.  Try out the recipes [here](https://evamaerey.github.io/mytidytuesday/2022-01-03-easy-geom-recipes/easy_geom_recipes.html).

- https://evamaerey.github.io/mytidytuesday/2022-01-03-easy-geom-recipes/easy_geom_recipes_flipbook.html#1
- https://evamaerey.github.io/mytidytuesday/2022-01-03-easy-geom-recipes/easy_geom_recipes.html
- https://raw.githubusercontent.com/EvaMaeRey/mytidytuesday/master/2022-01-03-easy-geom-recipes/easy_geom_recipes.Rmd

A go-to starting point for ggplot extension is theme.  But in my experience, though, using a home-grown theme pales to the thrill of seeing a home-grown geom -- doing a bunch of computational work in the background -- in action.  I think  more mathematically and statistically minded folks may have the same experience!  


# What's next?

The ggplot2 extension space is vast and includes the orthogonal components of ggplot2 builds (geoms, scales, coords, facets etc). Even within the space of new geoms, the strategies are varied. 


'Easy geom recipes' bites down into a little, exciting area of the ggplot2 extension space.  It expands the number of examples for that space and the material to play with this particular mechanism -- and lets new comers chew and linger on this the particular flavor of extension.  We hope that this tutorial gives folks a small win and makes more people curious about entering the ggplot extension space!  There is certainly more to terrain to cover, and perhaps we'll get to work on a 'just-a-tad-bit-harder geom recipes' soon.  


---

```{r ma206verse, include = F}
library(ggstamp)
ggcanvas() + 
  stamp_polygon(fill = "slateblue") + 
  stamp_text(label = "tidyverse") + 
  stamp_polygon(x0y0 = pos_honeycomb()[2,], fill = "darkred") + 
  stamp_text(label = "ggxmean", 
             xy = pos_honeycomb()[2,]) + 
  stamp_polygon(x0y0 = pos_honeycomb()[4,], fill = "darkolivegreen") + 
  stamp_text(label = "ma206data", 
             xy = pos_honeycomb()[4,]) + 
  stamp_polygon(x0y0 = pos_honeycomb()[5,], fill = "goldenrod4") + 
  stamp_text(label = "ggsample", 
             xy = pos_honeycomb()[5,]) + 
  stamp_polygon(radius = 3, alpha = .6, 
                x0 = 1, y = -.7)  + 
  stamp_text(label = "ma206verse", 
            x = 1, size = 15, y = -2,
            color = "gray15")
  
  
```



